{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSE 496AD - Lab 2 - Classification with Continuous Features\n",
    "In this lab you will implement two different methods for classification for problems with continuous features. You will implement the Naive Bayes classifier as well as Logistic Regression, verify their operation using a tiny dataset, and then compare the two approaches in a real world dataset. Additionally, you will train the Logistic Regression iteratively using Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy. You can do the first two questions in the lab with only Numpy.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This toy dataset will be used to verify correct operation of your algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy dataset of pets. length and height in cm, mass in kg.\n",
    "               #length, height,  mass\n",
    "X = np.array([[    107,     91,    52],  # bernese\n",
    "              [    122,     44,    79],  # great dane\n",
    "              [    107,     81,    34],  # goldie\n",
    "              [     64,     56,    24], # beagle\n",
    "              [     38,     25,     6],  # sphynx\n",
    "              [     36,     25,     5],  # siamese\n",
    "              [     44,     25,     5],  # persian\n",
    "              [     41,     30,     5]]) # manx\n",
    "Y = np.array([[\"dog\"],\n",
    "              [\"dog\"],\n",
    "              [\"dog\"],\n",
    "              [\"dog\"],\n",
    "              [\"cat\"],\n",
    "              [\"cat\"],\n",
    "              [\"cat\"],\n",
    "              [\"cat\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Naive Bayes Classifier (40 marks)\n",
    "In this section you will implement the functions for Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function called get_data which returns a smaller dataset of X including only the rows where Y is equal to y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data (X, Y, y_val):\n",
    "    '''\n",
    "    Gets all the rows of matrix X where Y is equal to y_val \n",
    "\n",
    "    X: A matrix with rows of features\n",
    "    Y: A column vector of labels\n",
    "    y_val: The value of Y where you wish to get rows of X\n",
    "    Returns a new matrix with selected rows of X \n",
    "    '''\n",
    "    # your code here\n",
    "    Z = np.where(Y[:]==y_val)[0]\n",
    "    N = X[Z]\n",
    "    return N\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xd:  [[107  91  52]\n",
      " [122  44  79]\n",
      " [107  81  34]\n",
      " [ 64  56  24]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "Xd:  [[107  91  52]\n",
    " [122  44  79]\n",
    " [107  81  34]\n",
    " [ 64  56  24]]\n",
    "'''\n",
    "Xd = get_data (X, Y, \"dog\")\n",
    "print(\"Xd: \", Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the mean function below\n",
    "# Takes a matrix of sampels, returns the mean as a row vector of means for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean (X):\n",
    "    '''\n",
    "    X: A matrix with rows of features\n",
    "    Returns a row vector of means, with one mean for each column\n",
    "    '''\n",
    "   \n",
    "    return np.mean(X,axis=0)\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean d:  [100.    68.    47.25]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "mean d:  [[100.    68.    47.25]]\n",
    "'''\n",
    "print (\"mean d: \", mean (Xd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variance function below\n",
    "# Takes a matrix of samples, returns sigma squared as a row vector of standard deviations for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance (X):\n",
    "    '''\n",
    "    X: A matrix with rows of features\n",
    "    Returns a row vector of standard deviations, with one standard deviation for each column\n",
    "    '''\n",
    "    means = mean(X)\n",
    "    minus = (X - means)**2\n",
    "    sumofminus = sum(minus)\n",
    "    return sumofminus/(X.shape[0]-1)\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviations d:  [[626.         472.66666667 582.25      ]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "standard deviations d:  [[626.         472.66666667 582.25      ]]\n",
    "'''\n",
    "print (\"standard deviations d: \", np.array([variance (Xd)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function below called class_labels\n",
    "# This function returns a simple list containing each of the unique values for Y, that is, the class labels for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_labels (Y):\n",
    "    '''\n",
    "    Y: A column vector of class labels\n",
    "    Returns a list containing each of the unique values in Y\n",
    "    '''\n",
    "    return np.unique(Y)\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels:  ['cat' 'dog']\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "class labels:  ['cat' 'dog']\n",
    "'''\n",
    "print(\"class labels: \", class_labels(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function below called get_likelihoods, as explained in the function docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihoods (x, X, Y):\n",
    "    '''\n",
    "    x: a row vector representing a sample for which you wish to compute likelihoods \n",
    "    X: the complete dataset with both classes\n",
    "    Y: the column vector of labels for the dataset\n",
    "\n",
    "    Returns a 2D array of likelihoods, with a row for each feature for the first class, \n",
    "    and a row for each feature of the second class\n",
    "    eg. [[P(X_1|Y=0), ... P(X_N|Y=0)]\n",
    "        [P(X_1|Y=1), ... P(X_N|Y=1)]]\n",
    "    This function should use all of the functions previously created\n",
    "    You may ignore P(Y=1), P(Y=2),... as they do not affect the arg_max for a balanced dataset\n",
    "    '''\n",
    "    dogclass = get_data(X, Y,\"dog\")\n",
    "    catclass = get_data(X, Y,\"cat\")\n",
    "    \n",
    "    dogmean = mean(dogclass)\n",
    "    catmean = mean(catclass)\n",
    "    dogvariance = variance(dogclass)\n",
    "    catvariance = variance(catclass)\n",
    "    result =[]\n",
    "    for i in range(3):\n",
    "        Z =  (math.sqrt(2*math.pi*catvariance[i]))**-1\n",
    "        I = (x[0][i]-catmean[i])**2/(2*catvariance[i])\n",
    "        result.append((Z*np.exp(1)**-I))        \n",
    "    for i in range(3):\n",
    "        Z =  (math.sqrt(2*math.pi*dogvariance[i]))**-1\n",
    "        I = (x[0][i]-dogmean[i])**2/(2*dogvariance[i])\n",
    "        result.append((Z*np.exp(1)**-I))\n",
    "    B = np.reshape(result, (-1, 3))\n",
    "    return B\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liklihoods [[4.53829013e-02 5.18070383e-02 7.04130654e-01]\n",
      " [5.45823793e-04 3.98332943e-03 3.56964591e-03]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "liklihoods [[4.53829013e-02 5.18070383e-02 7.04130654e-01]\n",
    " [5.45823793e-04 3.98332943e-03 3.56964591e-03]]\n",
    "'''\n",
    "x = [[35, 30, 5]]\n",
    "print (\"liklihoods\", get_likelihoods(x, X, Y))\n",
    "Z =get_likelihoods(x, X, Y)\n",
    "I =np.prod(Z,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called prediction, which predicts the class for a test sample as explained in the function docstring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction (x, X, Y):\n",
    "    '''\n",
    "    x is a row vector representing a new sample for classification\n",
    "    X is the complete dataset with both classes\n",
    "    Y is the column vector of labels for the dataset\n",
    "    Return a string value representing the label \n",
    "    '''\n",
    "    likelihoods = get_likelihoods(x, X, Y)\n",
    "    afterProduct = np.prod(likelihoods, axis=1)\n",
    "    y = np.argmax(afterProduct)\n",
    "    return class_labels(Y)[y]\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction cat\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "prediction cat\n",
    "'''\n",
    "print (\"prediction\", prediction(x, X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (cat):  cat\n",
      "prediction (newfoundland):  dog\n",
      "prediction (yorkie):  cat\n",
      "prediction (lion):  dog\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test cell\n",
    "Expected output:\n",
    "prediction (cat):  cat\n",
    "prediction (newfoundland):  dog\n",
    "prediction (yorkie):  cat\n",
    "prediction (lion):  dog\n",
    "'''\n",
    "\n",
    "x = [[35, 30, 5]] # cat\n",
    "print(\"prediction (cat): \", prediction(x, X, Y))\n",
    "\n",
    "x = [[107, 95, 54]] #newfoundland\n",
    "print(\"prediction (newfoundland): \", prediction(x, X, Y))\n",
    "\n",
    "# Just for fun, some examples we expect to be classified wrong\n",
    "x = [[39, 33, 7]] # yorkie\n",
    "print(\"prediction (yorkie): \", prediction(x, X, Y))\n",
    "\n",
    "x = [[137, 112, 190]] # lion\n",
    "print(\"prediction (lion): \", prediction(x, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Logistic Regression (40 marks)\n",
    "In this portion of the notebook you will implement logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize w as a colum vector with values -1, 1, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "w = np.array ([[-1],\n",
    "               [1],\n",
    "               [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1-hot encoded Y vector, where \"dog\"=1 and \"cat\"=0\n",
    "#Y =(Y[:]==\"dog\")*1\n",
    "Yd = np.array([[1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called dense which implements the linear part of the logisitic regression node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense (X, w):\n",
    "    '''\n",
    "    Performs the linear combination part of the logistic regression node\n",
    "    X: a matrix of samples, with samples in rows and features in columns\n",
    "    w: a column vector of weights, with 1 weight per feature\n",
    "    Returns z, a column vector with a value for each sample\n",
    "    '''\n",
    "    z = np.array(np.dot(X,w))\n",
    "\n",
    "    return z\n",
    "    \n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z [[ 36]\n",
      " [  1]\n",
      " [  8]\n",
      " [ 16]\n",
      " [ -7]\n",
      " [ -6]\n",
      " [-14]\n",
      " [ -6]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output with initial value for w:\n",
    "z [[ 36]\n",
    " [  1]\n",
    " [  8]\n",
    " [ 16]\n",
    " [ -7]\n",
    " [ -6]\n",
    " [-14]\n",
    " [ -6]]\n",
    "'''\n",
    "\n",
    "z = dense(X, w)\n",
    "print (\"z\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called sigmoid which implements the sigmoid part of the logistic regression node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (z):\n",
    "    '''\n",
    "    Performs the sigmoid part of the logistic regression node\n",
    "    z: the output of dense function\n",
    "    Returns: a column vector the class predictions probabilities for each sample\n",
    "    '''\n",
    "    return (1+np.exp(1)**-z)**-1\n",
    "    \n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hat [[1.00000000e+00]\n",
      " [7.31058579e-01]\n",
      " [9.99664650e-01]\n",
      " [9.99999887e-01]\n",
      " [9.11051194e-04]\n",
      " [2.47262316e-03]\n",
      " [8.31528028e-07]\n",
      " [2.47262316e-03]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output with initial value for w:\n",
    "a [[1.00000000e+00]\n",
    " [7.31058579e-01]\n",
    " [9.99664650e-01]\n",
    " [9.99999887e-01]\n",
    " [9.11051194e-04]\n",
    " [2.47262316e-03]\n",
    " [8.31528028e-07]\n",
    " [2.47262316e-03]]\n",
    "'''\n",
    "\n",
    "Y_hat = sigmoid(z)\n",
    "print (\"Y_hat\", Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called log loss which computes the log loss for a given prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss (Y, Y_hat):\n",
    "    '''\n",
    "    Y: A 1-hot column vector encoded of labels\n",
    "    Y_hat: A column vector of predicted probabilities\n",
    "    Returns the sum of log loss for each prediction vs. the actual value\n",
    "    '''\n",
    "    \n",
    "    lw = -Y*(np.log(Y_hat)) - (1-Y)*(np.log((1-Y_hat)))\n",
    "    return np.sum(lw)\n",
    "    # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll 0.31946087468389556\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output with initial value for w:\n",
    "ll 0.31946087468389556\n",
    "'''\n",
    "\n",
    "log_loss_val = log_loss(Yd, Y_hat)\n",
    "print (\"ll\", log_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called gradient_log_loss which computes the gradient of the log loss function with respect to the vector of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_log_loss (X, Y, w):\n",
    "    '''\n",
    "    X: A matrix of samples, with samples in rows and features in columns\n",
    "    Y: A 1-hot column vector encoded of labels\n",
    "    w: A column vector of weights, with one weight for each feature\n",
    "    Returns the gradient of the log_loss function at this point\n",
    "    '''\n",
    "    \n",
    "    z = dense(X, w)\n",
    "\n",
    "    Y_hat = sigmoid(z)\n",
    "  \n",
    "    U = Y_hat-Y\n",
    "    C = X.transpose()\n",
    "    gll = np.dot(C,U)\n",
    "    return gll\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gll [[-32.62169456]\n",
      " [-11.70180086]\n",
      " [-21.2275802 ]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output with initial value for w:\n",
    "gll [[-32.62169456]\n",
    " [-11.70180086]\n",
    " [-21.2275802 ]]\n",
    "'''\n",
    "\n",
    "gradient_log_loss_val = gradient_log_loss (X, Yd, w)\n",
    "print (\"gll\", gradient_log_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called update which updates the weights based on the gradient log loss as a given set of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update (X, Y, w, alpha):\n",
    "    '''\n",
    "    Performs a single iteration of gradient descent. Computes the gradients and updates the weights.\n",
    "    X: A matrix of samples, with samples in rows and features in columns\n",
    "    Y: A 1-hot column vector encoded from the labels\n",
    "    w: A column vector of weights, with one weight for each feature\n",
    "    alpha: The step size for gradient descent\n",
    "    '''\n",
    "    gradient = gradient_log_loss(X,Y,w)\n",
    "    neww = w - (alpha*gradient)\n",
    "    return neww\n",
    "    # your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [[-0.96737831]\n",
      " [ 1.0117018 ]\n",
      " [ 1.02122758]]\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output with initial value for w:\n",
    "w [[-0.96737831]\n",
    " [ 1.0117018 ]\n",
    " [ 1.02122758]]\n",
    "'''\n",
    "\n",
    "alpha = 0.001\n",
    "x = update (X, Yd, w, alpha)\n",
    "print (\"w\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called \"train\" which is implemented as per the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (X, Y, w, alpha, epochs):\n",
    "    '''\n",
    "    Trains the weights for logistic regression by performing multiple iterations of gradient descent\n",
    "\n",
    "    X: A Matrix of training input features\n",
    "    Y: A 1-hot column vector of training output features\n",
    "    w: The initialized weight vector\n",
    "    alpha: The step size in gradient descent\n",
    "    epochs: The number of iterations for which the model will be trained\n",
    "    '''\n",
    "    temp = float('inf')\n",
    "    for i in range(epochs):\n",
    "        z = dense(X, w)\n",
    "        Y_hat = sigmoid(z)\n",
    "        log_loss_val = log_loss(Yd, Y_hat)\n",
    "        if log_loss_val > temp:\n",
    "            return w\n",
    "        else:\n",
    "            w = update(X, Y, w, alpha)\n",
    "            temp = log_loss_val\n",
    "    return w    \n",
    "    # your code here\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-491-d5fd5906690b>:8: RuntimeWarning: divide by zero encountered in log\n",
      "  lw = -Y*(np.log(Y_hat)) - (1-Y)*(np.log((1-Y_hat)))\n",
      "<ipython-input-491-d5fd5906690b>:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  lw = -Y*(np.log(Y_hat)) - (1-Y)*(np.log((1-Y_hat)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [[-1.00539839]\n",
      " [ 0.92809851]\n",
      " [ 1.17363023]]\n"
     ]
    }
   ],
   "source": [
    "# train your model with the following settings:\n",
    "#  5000 training epochs with alpha=0.001 \n",
    "''' Test cell\n",
    "Expected output w after training, 5000 steps + 1 in a previous cell:\n",
    "w [[-1.00540176]\n",
    " [ 0.92809876]\n",
    " [ 1.1736416 ]]\n",
    "'''\n",
    "alpha = 0.001\n",
    "epochs = 5000\n",
    "w = train (X, Yd, w, alpha, epochs)\n",
    "print (\"w\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function called logistic_predict which returns the true_label if the prediction probability > 0.5, else return false_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predict (x, w, true_label, false_label):\n",
    "    '''\n",
    "    x: a test sample or matrix\n",
    "    w: the trained weight vector\n",
    "    true_label: the label to return if the prediction probability is greater than 0.5\n",
    "    false_label: the label to return otherwise\n",
    "    returns a pre\n",
    "    diction or array of predictions using logistic regression\n",
    "    '''\n",
    "    z = dense(x, w)\n",
    "    Y_hat = sigmoid(z)\n",
    "    if Y_hat>0.5:\n",
    "        return true_label\n",
    "    else:\n",
    "        return false_label\n",
    "    \n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (cat):  cat\n",
      "prediction (newfoundland):  dog\n",
      "prediction (yorkie):  cat\n",
      "prediction (lion):  dog\n"
     ]
    }
   ],
   "source": [
    "''' Test cell\n",
    "Expected output:\n",
    "prediction (cat):  cat\n",
    "prediction (newfoundland):  dog\n",
    "prediction (yorkie):  cat\n",
    "prediction (lion):  dog\n",
    "'''\n",
    "x = [[35, 30, 5]] # cat\n",
    "print(\"prediction (cat): \", logistic_predict(x, w, \"dog\", \"cat\"))\n",
    "\n",
    "x = [[107, 95, 54]] #newfoundland\n",
    "print(\"prediction (newfoundland): \", logistic_predict(x, w, \"dog\", \"cat\"))\n",
    "\n",
    "# Just for fun, some examples we expect to be wrong\n",
    "\n",
    "x = [[39, 33, 7]] # yorkie\n",
    "print(\"prediction (yorkie): \", logistic_predict(x, w, \"dog\", \"cat\"))\n",
    "\n",
    "x = [[137, 112, 190]] # lion\n",
    "print(\"prediction (lion): \", logistic_predict(x, w, \"dog\", \"cat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Testing our algorithms on a real world dataset (20 Marks)\n",
    "\n",
    "The final section of this workbook tests out these algorithms on real world datasets. In particular, you will load up the Telco dataset which analyzes customer behaviour to assess customer retention. In business, the term \"Churn\" is used to refer to customers who ceased using your service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas using the canonical import statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and test datasets, which have been balanced and shuffled for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "training = pd.read_csv(\"telco-churn-train.csv\")\n",
    "test = pd.read_csv(\"telco-churn-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the training dataset to see the names of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2986 entries, 0 to 2985\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        2986 non-null   object \n",
      " 1   gender            2986 non-null   object \n",
      " 2   SeniorCitizen     2986 non-null   int64  \n",
      " 3   Partner           2986 non-null   object \n",
      " 4   Dependents        2986 non-null   object \n",
      " 5   tenure            2986 non-null   int64  \n",
      " 6   PhoneService      2986 non-null   object \n",
      " 7   MultipleLines     2986 non-null   object \n",
      " 8   InternetService   2986 non-null   object \n",
      " 9   OnlineSecurity    2986 non-null   object \n",
      " 10  OnlineBackup      2986 non-null   object \n",
      " 11  DeviceProtection  2986 non-null   object \n",
      " 12  TechSupport       2986 non-null   object \n",
      " 13  StreamingTV       2986 non-null   object \n",
      " 14  StreamingMovies   2986 non-null   object \n",
      " 15  Contract          2986 non-null   object \n",
      " 16  PaperlessBilling  2986 non-null   object \n",
      " 17  PaymentMethod     2986 non-null   object \n",
      " 18  MonthlyCharges    2986 non-null   float64\n",
      " 19  TotalCharges      2986 non-null   float64\n",
      " 20  Churn             2986 non-null   object \n",
      "dtypes: float64(2), int64(2), object(17)\n",
      "memory usage: 490.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 752 entries, 0 to 751\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        752 non-null    object \n",
      " 1   gender            752 non-null    object \n",
      " 2   SeniorCitizen     752 non-null    int64  \n",
      " 3   Partner           752 non-null    object \n",
      " 4   Dependents        752 non-null    object \n",
      " 5   tenure            752 non-null    int64  \n",
      " 6   PhoneService      752 non-null    object \n",
      " 7   MultipleLines     752 non-null    object \n",
      " 8   InternetService   752 non-null    object \n",
      " 9   OnlineSecurity    752 non-null    object \n",
      " 10  OnlineBackup      752 non-null    object \n",
      " 11  DeviceProtection  752 non-null    object \n",
      " 12  TechSupport       752 non-null    object \n",
      " 13  StreamingTV       752 non-null    object \n",
      " 14  StreamingMovies   752 non-null    object \n",
      " 15  Contract          752 non-null    object \n",
      " 16  PaperlessBilling  752 non-null    object \n",
      " 17  PaymentMethod     752 non-null    object \n",
      " 18  MonthlyCharges    752 non-null    float64\n",
      " 19  TotalCharges      752 non-null    float64\n",
      " 20  Churn             752 non-null    object \n",
      "dtypes: float64(2), int64(2), object(17)\n",
      "memory usage: 123.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6987-XQSJT</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>54</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>79.50</td>\n",
       "      <td>4370.25</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4686-UXDML</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>21</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>99.85</td>\n",
       "      <td>1992.55</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5066-GFJMM</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.90</td>\n",
       "      <td>45.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104-TNLZA</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>28</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>105.80</td>\n",
       "      <td>2998.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7931-PXHFC</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>62.30</td>\n",
       "      <td>2354.80</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  6987-XQSJT  Female              1      No         No      54          Yes   \n",
       "1  4686-UXDML  Female              0      No         No      21          Yes   \n",
       "2  5066-GFJMM  Female              0     Yes         No       3          Yes   \n",
       "3  1104-TNLZA    Male              1     Yes         No      28          Yes   \n",
       "4  7931-PXHFC    Male              0      No         No      38          Yes   \n",
       "\n",
       "  MultipleLines InternetService       OnlineSecurity  ...  \\\n",
       "0           Yes     Fiber optic                   No  ...   \n",
       "1           Yes     Fiber optic                   No  ...   \n",
       "2            No              No  No internet service  ...   \n",
       "3           Yes     Fiber optic                   No  ...   \n",
       "4            No             DSL                   No  ...   \n",
       "\n",
       "      DeviceProtection          TechSupport          StreamingTV  \\\n",
       "0                   No                   No                   No   \n",
       "1                   No                   No                  Yes   \n",
       "2  No internet service  No internet service  No internet service   \n",
       "3                   No                  Yes                  Yes   \n",
       "4                  Yes                  Yes                   No   \n",
       "\n",
       "       StreamingMovies        Contract PaperlessBilling  \\\n",
       "0                   No  Month-to-month              Yes   \n",
       "1                  Yes  Month-to-month              Yes   \n",
       "2  No internet service  Month-to-month              Yes   \n",
       "3                  Yes  Month-to-month              Yes   \n",
       "4                  Yes        One year              Yes   \n",
       "\n",
       "             PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0         Electronic check          79.50       4370.25    Yes  \n",
       "1  Credit card (automatic)          99.85       1992.55     No  \n",
       "2             Mailed check          19.90         45.75     No  \n",
       "3         Electronic check         105.80       2998.00     No  \n",
       "4             Mailed check          62.30       2354.80    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "training.info()\n",
    "test.info()\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Y vector for each the training and test sets by selecting an appropriate output column from the train and test datasets.\n",
    "# What is the name of the column? What are the possible class labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array([training[\"SeniorCitizen\"]])# your code here\n",
    "Y_train = Y_train.transpose()\n",
    "Y_test  = np.array([training[\"SeniorCitizen\"]])# your code here\n",
    "Y_test = Y_test.transpose()\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the training data with columns for tenure, monthly charges and total charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([training[\"tenure\"],training[\"MonthlyCharges\"],training[\"TotalCharges\"]])# your code here\n",
    "X_test  = np.array([test[\"tenure\"], test[\"MonthlyCharges\"],test[\"TotalCharges\"]])# your code here\n",
    "X_train = X_train.transpose()\n",
    "X_test = X_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to compare the two models. Using the training set, train a model using both Naive Bayes and Logistic Regression. Compute the training error and test error. To complete this, implement the two functions descibed below and run the function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_naive_bayes (X_train, X_test, Y_train, Y_test):\n",
    "    '''\n",
    "    Trains the Naive Bayes classifier using the X_train and Y_train, and then tests the\n",
    "    model on X_test and Y_test. Counts and displays the number of correctly classified samples, \n",
    "    the total number of samples, and the accuracy of the model.\n",
    "    X_train: The training dataset\n",
    "    X_test: The test dataset\n",
    "    Y_train: The training labels\n",
    "    Y_test: The test labels\n",
    "    '''\n",
    "    seniorCitzenClass = get_data(X_train, Y_train,1)\n",
    "    noSeniorCitzenClass = get_data(X_train, Y_train,0)\n",
    "    \n",
    "    seniorCitzenmean = mean(seniorCitzenClass)\n",
    "    noSeniorCitzenmean = mean(noSeniorCitzenClass)\n",
    "    seniorCitzenvariance = variance(seniorCitzenClass)\n",
    "    noSeniorCitzenvariance = variance(noSeniorCitzenClass)\n",
    "    result = []\n",
    "    def getLikelihoods(index):\n",
    "        for i in range(3):\n",
    "            Z =  1/(math.sqrt(2*math.pi*noSeniorCitzenvariance[i]))\n",
    "            I = (X_test[index][i]-noSeniorCitzenmean[i])**2/(2*noSeniorCitzenvariance[i])\n",
    "            result.append((Z*np.exp(1)**-I)) \n",
    "        for i in range(3):\n",
    "            Z =  1/(math.sqrt(2*math.pi*seniorCitzenvariance[i]))\n",
    "            I = (X_test[index][i]-seniorCitzenmean[i])**2/(2*seniorCitzenvariance[i])\n",
    "            result.append((Z*np.exp(1)**-I))\n",
    "        return result \n",
    "    z = []\n",
    "    for index in range(len(X_test)): \n",
    "        B = np.reshape(getLikelihoods(index), (-1, 3)) \n",
    "        result =[]\n",
    "        afterProduct = np.prod(B, axis=1)\n",
    "        z.append(np.argmax(afterProduct))\n",
    "    Z = np.reshape(z,(-1,1)) # tge predict result \n",
    "    counter = 0\n",
    "    for i in range(len(X_test)):\n",
    "        if Z[i] == Y_test[i]:\n",
    "            counter +=1\n",
    "    accuracy = counter/len(X_test)\n",
    "    print(accuracy)\n",
    "    # your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5452109845947756\n"
     ]
    }
   ],
   "source": [
    "# Assess training accuracy of Naive Bayes \n",
    "test_naive_bayes(X_train,X_train, Y_train, Y_train)\n",
    "#test_naive_bayes (np.array(X_train), np.array(X_train), np.array([Y_train]).T, np.array([Y_train]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4734042553191489\n"
     ]
    }
   ],
   "source": [
    "# Assess test accuracy of Naive Bayes \n",
    "#test_naive_bayes (np.array(X_train), np.array(X_test), np.array([Y_train]).T, np.array([Y_test]).T)\n",
    "test_naive_bayes(X_train,X_test,Y_train,Y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-488-b0bfcbd09808>:7: RuntimeWarning: overflow encountered in power\n",
      "  return (1+np.exp(1)**-z)**-1\n",
      "<ipython-input-491-d5fd5906690b>:8: RuntimeWarning: divide by zero encountered in log\n",
      "  lw = -Y*(np.log(Y_hat)) - (1-Y)*(np.log((1-Y_hat)))\n",
      "<ipython-input-491-d5fd5906690b>:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  lw = -Y*(np.log(Y_hat)) - (1-Y)*(np.log((1-Y_hat)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (3,2986) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-522-9e36edd17344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# your code here - Reminder: Create a 1-hot column for Y, and then train using the supplied hyper-parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-503-d3b46e67d72b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, Y, w, alpha, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-500-edf6ca993056>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(X, Y, w, alpha)\u001b[0m\n\u001b[0;32m      8\u001b[0m     '''\n\u001b[0;32m      9\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_log_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mneww\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mneww\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (3,2986) "
     ]
    }
   ],
   "source": [
    "# train the logistic regression classifier on the telco dataset with the following settings:\n",
    "# 5000 training epochs with alpha=0.001 \n",
    "w = [1,1,-1]\n",
    "alpha = 0.01\n",
    "epochs = 500\n",
    "# your code here - Reminder: Create a 1-hot column for Y, and then train using the supplied hyper-parameters\n",
    "train(X_train, Y_train, w, alpha, epochs)\n",
    "print (\"w\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement and run the following function to test the logistic regression model on the real world dataet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_logistic_regression (X_test, Y_test, w):\n",
    "    '''\n",
    "    Tests the trained Logistic Regression classifier using a test dataset.\n",
    "    Counts and displays the number of correctly classified samples, the total number of \n",
    "    samples, and the accuracy of the model.\n",
    "    X_test: The test dataset\n",
    "    Y_test: The test labels\n",
    "    w: The trained weights\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the training error of the logistic regression model\n",
    "test_logistic_regression (np.array(X_train), np.array([Y_train]).T, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the test error of the logistic regression model\n",
    "test_logistic_regression (np.array(X_test), np.array([Y_test]).T, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For verification, expected training accuracies for the two models, not necessarily in order:  \n",
    "0.6872069658405894\n",
    "0.7073007367716008\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
